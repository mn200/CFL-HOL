\section{Related work}

In the general area of mechanised language theory, the earliest work we are aware of is by \citeauthor{nipkow98}~(\citeyear{nipkow98}).
That paper describes a verified and executable lexical analyzer generator.
%
Focusing on core language theory as it does, we feel this work is the closest in nature to our own mechanisation, though of course it covers regular rather than context-free languages.

Apart from our own earlier work on SLR parsing, there have recently been a number of papers directly concerned with mechanisation and verification of specific approaches to parsing.
For example, \cite{koprowski11:trx} describe the construction of a verified parser for \emph{expression grammars}.
This formalism allows for parsers for a large class of languages to be generated from natural specifications that look a great deal like context-free grammars.
Another example is \cite{ridge2011:cfg-parsing}, which work presents a verified parser for all possible context-free grammars, using an admirably simple algorithm.
The drawback is that, as presented, the algorithm is of complexity~$O(n^5)$.

Parser combinators, popular in functional programming languages, are another approach to the general parsing problem, and there has been some mechanisation work in this area.
For example, \citet{Danielsson2010:TPC} presents a library of parser combinators that have been verified (in the Agda system) to guarantee termination of parsing.


\section{Conclusions}

We have mechanised a large portion of the background theory of context-free grammars and pushdown automata.
%
This theory is fundamental to an important part of computer science, and had not been mechanised previously.
%
The work was pursued as part of a larger project (the first author's PhD): to mechanise one of the field's standard textbooks.
And, just as a textbook lays the foundation for future research, we hope our mechanised theories provide a platform for others' work in the area of context-free languages.
%

Inevitably, the mechanisation work occasioned a great many instances of ``proof blowup'', where something handled briefly in prose turns out to require a great deal of toil.
Most of this was simple tedium (necessary inductions are very easy for humans to glide past); at other times, the effort seem to require rather more human ingenuity.
A numerical summary of the blood, sweat and tears \emph{per} theory appears in Table~\ref{tab:numbers}.
The total person-time taken was in the order of one PhD student multiplied by 6 months.

\begin{table}
\begin{center}
\begin{tabular}{lrrr}
  \textbf{Theory}&\textbf{LOC}&\textbf{\#Definitions}&\textbf{\#Proofs}\\
  \hline
  CFGs---background       & 3680 & 36 & 189 \\
  PDAs---background        & 1846 & 15 & 47 \\
  Empty Stack Acceptance $\iff$ Final State Acceptance & 1795 & 6 & 75 \\
  PDA $\iff$ CFG & 2598 & 16 & 50\\
  Closure properties & 1686 & 12 & 91\\
\end{tabular}
\end{center}
\caption{Summary of proof effort}
\label{tab:numbers}
\end{table}

Despite these issues around proof-size explosion, we also hope our mechanisation might be a good basis for teaching language theory.
Others, such as \citet{pate07} and \citet{Pierce:LambdaTA-ITP} have used the Coq system as part of courses on logic, mathematics and topics in theoretical computer science.
Given its central part in the curriculum, and given our success in the mechanisation of Hopcroft and Ullman, we now believe language theory to be an area well-suited to mechanised pedagogy.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "pda"
%%% End:

% LocalWords:  CFG combinators Agda Coq Hopcroft Ullman
